{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json_lines\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import lxml.etree as etree # to create gexl file\n",
    "import datetime\n",
    "\n",
    "import geopandas\n",
    "import geopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find 10,000 influential users ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract and measure user influence\n",
    "\n",
    "def load_jsonl(file):\n",
    "    tweets = []\n",
    "    with open(file, 'rb') as f:\n",
    "        for tweet in json_lines.reader(f, broken=True): \n",
    "            reduced_tweet = {\n",
    "                'created_at'    : tweet['created_at'],\n",
    "                'id'            : tweet['id_str'],\n",
    "                'text'          : tweet['full_text'],\n",
    "                'retweet_count' : tweet['retweet_count'],               \n",
    "                'like_count'    : tweet['favorite_count'],\n",
    "                \n",
    "                'reply_user_id' : tweet['in_reply_to_user_id_str'],\n",
    "                'reply_id'      : tweet['in_reply_to_status_id_str'],\n",
    "                'reply_username': tweet['in_reply_to_screen_name'],\n",
    "\n",
    "                'username'    : tweet['user']['screen_name'],\n",
    "                'user_joined' : tweet['user']['created_at'][-4:],\n",
    "                'user_id'     : tweet['user']['id_str'],\n",
    "                'location'    : tweet['user']['location'],\n",
    "                'followers'   : tweet['user']['followers_count'],\n",
    "                'friends'     : tweet['user']['friends_count']\n",
    "            }               \n",
    "            if 'retweeted_status' in tweet:\n",
    "                reduced_tweet['retweets'] = {\n",
    "                    'created_at'    : tweet['retweeted_status']['created_at'],\n",
    "                    'id'            : tweet['retweeted_status']['id_str'],\n",
    "                    'text'          : tweet['retweeted_status']['full_text'],\n",
    "                    'retweet_count' : tweet['retweeted_status']['retweet_count'],               \n",
    "                    'like_count'    : tweet['retweeted_status']['favorite_count'],               \n",
    "\n",
    "                    'username'    : tweet['retweeted_status']['user']['screen_name'],\n",
    "                    'user_joined' : tweet['retweeted_status']['user']['created_at'][-4:],\n",
    "                    'user_id'     : tweet['retweeted_status']['user']['id_str'],\n",
    "                    'location'    : tweet['retweeted_status']['user']['location'],         \n",
    "                    'followers'   : tweet['retweeted_status']['user']['followers_count'],\n",
    "                    'friends'     : tweet['retweeted_status']['user']['friends_count'],\n",
    "                }\n",
    "            if 'quoted_status' in tweet:\n",
    "                reduced_tweet['quotes'] = {\n",
    "                    'created_at'    : tweet['quoted_status']['created_at'],\n",
    "                    'id'            : tweet['quoted_status']['id_str'],\n",
    "                    'text'          : tweet['quoted_status']['full_text'],\n",
    "                    'retweet_count' : tweet['quoted_status']['retweet_count'],               \n",
    "                    'like_count'    : tweet['quoted_status']['favorite_count'],               \n",
    "\n",
    "                    'username'    : tweet['quoted_status']['user']['screen_name'],\n",
    "                    'user_joined' : tweet['quoted_status']['user']['created_at'][-4:],\n",
    "                    'user_id'     : tweet['quoted_status']['user']['id_str'],\n",
    "                    'location'    : tweet['quoted_status']['user']['location'],         \n",
    "                    'followers'   : tweet['quoted_status']['user']['followers_count'],\n",
    "                    'friends'     : tweet['quoted_status']['user']['friends_count'],\n",
    "                }    \n",
    "\n",
    "            tweets.append(reduced_tweet)\n",
    "        return (tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract and measure user influence by file\n",
    "for i in range(0,4):\n",
    "    \n",
    "    tweets = load_jsonl(r\"D:\\twarc\\climatetweetID\\hydratefile\\climate_id_0%d.jsonl\" % (i))\n",
    "    pdtweet = pd.DataFrame(tweets)\n",
    "    \n",
    "    ori_tweet = pdtweet[pdtweet['retweets'].apply(lambda x: type(x) != dict)]\n",
    "    \n",
    "    # user unique information: (user name, id, location, followers)\n",
    "    user_info = ori_tweet.drop_duplicates(subset = ['user_id'])\n",
    "    user_info = user_info[[\"username\",\"user_id\",\"location\",\"followers\",\"friends\"]]\n",
    "    user_info.to_csv(r\"D:\\twarc\\climatetweetID\\tweets_prediction\\influence\\allusers_info\\output_2\\user_%d.csv\" % (i))\n",
    "    \n",
    "    # user tweets summary: (retweet count, like count, id)\n",
    "    tweetinfluence = ori_tweet.groupby('user_id').agg({\n",
    "        'retweet_count' : 'sum',\n",
    "        'like_count'    : 'sum',\n",
    "        'id' : 'count'\n",
    "    }).sort_values(by = ['retweet_count'], ascending=False)\n",
    "    tweetinfluence.to_csv(r\"D:\\twarc\\climatetweetID\\tweets_prediction\\influence\\allusers_info\\output_2\\influence_%d.csv\" % (i))\n",
    "  \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge files and select top 10,000 influential users\n",
    "influence = pd.DataFrame()\n",
    "for i in range(0,4):\n",
    "    influence_ = pd.read_csv(r\"D:\\twarc\\climatetweetID\\tweets_prediction\\influence\\allusers_info\\output_2\\influence_%d.csv\" % (i),dtype=object)\n",
    "    influence = influence.append(influence_)\n",
    "influence = influence.reset_index(drop=True)\n",
    "influence = influence.astype({'retweet_count': 'int32',\n",
    "                              'like_count': 'int32',\n",
    "                              'id': 'int32'})\n",
    "influence = influence.groupby('user_id', as_index=False).agg({\n",
    "        'retweet_count' : 'sum',\n",
    "        'like_count'    : 'sum',\n",
    "        'id' : 'sum'})\n",
    "influence['influence'] = influence['retweet_count'] + influence['like_count']\n",
    "influence = influence.sort_values(by = ['influence'], ascending=False)\n",
    "\n",
    "# users info\n",
    "userinfo = pd.DataFrame()\n",
    "for i in range(0,4):\n",
    "    userinfo_ = pd.read_csv(r\"D:\\twarc\\climatetweetID\\tweets_prediction\\influence\\allusers_info\\output_2\\user_%d.csv\" % (i),dtype=object)\n",
    "    userinfo  = userinfo.append(userinfo_)\n",
    "\n",
    "userinfo = userinfo.drop_duplicates(subset = ['user_id'])\n",
    "userinfo = userinfo.reset_index(drop=True)\n",
    "userinfo = userinfo.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# join top users and user information\n",
    "influence = influence.set_index('user_id').join(userinfo.set_index('user_id'))\n",
    "influence = influence.sort_values(by = ['influence'], ascending=False).reset_index()\n",
    "influence = influence.rename(columns = {'id':'total_tweet'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select the top 10,000 and save\n",
    "with open(r\"D:\\twarc\\climatetweetID\\tweets_prediction\\influence\\allusers_info\\output_3\\topinfluencer.txt\", \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(influence.head(5000), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location(Michigan, United States, (43.6211955, -84.6824346, 0.0))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locator = geopy.Nominatim(user_agent= 'myGeocoder')\n",
    "location = locator.geocode(\"michigan\")\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select tweets only in the US\n",
    "with open(r\"D:\\twarc\\climatetweetID\\tweets_prediction\\influence\\allusers_info\\output_3\\topinfluencer.txt\", \"rb\") as fp:   #Pickling\n",
    "    user = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('L.A., Calif.',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 426, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 421, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 1332, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 303, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 264, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 428, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 724, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\util\\retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=L.A.%2C+Calif.&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 387, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 543, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=L.A.%2C+Calif.&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 360, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 377, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 399, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=L.A.%2C+Calif.&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('L.A., Calif.',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 426, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 421, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 1332, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 303, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 264, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 428, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 724, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\util\\retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=L.A.%2C+Calif.&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 387, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 543, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=L.A.%2C+Calif.&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 360, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 377, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 399, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=L.A.%2C+Calif.&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter swallowed an error after 2 retries. Called with (*('L.A., Calif.',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 426, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 421, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 1332, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 303, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 264, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 428, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 724, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\util\\retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=L.A.%2C+Calif.&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 387, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 543, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=L.A.%2C+Calif.&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 360, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 377, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 399, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=L.A.%2C+Calif.&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('San Francisco/New York',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 426, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 421, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 1332, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 303, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 264, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 428, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 724, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\util\\retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=San+Francisco%2FNew+York&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 387, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 543, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=San+Francisco%2FNew+York&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 360, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 377, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 399, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=San+Francisco%2FNew+York&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('San Francisco/New York',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 426, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 421, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 1332, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 303, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 264, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 428, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 724, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\util\\retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=San+Francisco%2FNew+York&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 387, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 543, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=San+Francisco%2FNew+York&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 360, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 377, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 399, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=San+Francisco%2FNew+York&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('San Francisco/New York',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 426, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 421, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 1332, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 303, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 264, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 428, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 724, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\util\\retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=San+Francisco%2FNew+York&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 387, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 543, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=San+Francisco%2FNew+York&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 360, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 377, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 399, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=San+Francisco%2FNew+York&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('London / New York / Hong Kong',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 426, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 421, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 1332, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 303, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 264, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 428, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 724, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\util\\retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=London+%2F+New+York+%2F+Hong+Kong&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 387, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 543, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=London+%2F+New+York+%2F+Hong+Kong&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 360, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 377, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 399, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=London+%2F+New+York+%2F+Hong+Kong&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('London / New York / Hong Kong',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 426, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 421, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 1332, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 303, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 264, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 428, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 724, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\util\\retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=London+%2F+New+York+%2F+Hong+Kong&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 387, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 543, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=London+%2F+New+York+%2F+Hong+Kong&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 360, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 377, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 399, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=London+%2F+New+York+%2F+Hong+Kong&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter swallowed an error after 2 retries. Called with (*('London / New York / Hong Kong',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 426, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 421, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 1332, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 303, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 264, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 428, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 724, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\util\\retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=London+%2F+New+York+%2F+Hong+Kong&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 387, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 543, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=London+%2F+New+York+%2F+Hong+Kong&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 360, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 377, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 399, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=London+%2F+New+York+%2F+Hong+Kong&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('1420405751 ...Home',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 426, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 421, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 1332, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 303, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 264, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 428, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 724, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\util\\retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1420405751+...Home&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 387, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 543, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1420405751+...Home&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 360, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 377, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 399, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1420405751+...Home&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('1420405751 ...Home',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 426, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 421, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 1332, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 303, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 264, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 428, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 724, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\util\\retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1420405751+...Home&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 387, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 543, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1420405751+...Home&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 360, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 377, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 399, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1420405751+...Home&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('1420405751 ...Home',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 426, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 421, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 1332, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 303, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 264, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 428, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 724, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\util\\retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1420405751+...Home&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 387, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 543, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1420405751+...Home&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 360, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 377, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 399, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=1420405751+...Home&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*(' in Cape Town ',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 426, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 421, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 1332, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 303, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 264, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 428, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 724, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\util\\retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=%F0%9F%87%B3%F0%9F%87%AC+in+Cape+Town+%F0%9F%87%BF%F0%9F%87%A6&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 387, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 543, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=%F0%9F%87%B3%F0%9F%87%AC+in+Cape+Town+%F0%9F%87%BF%F0%9F%87%A6&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 360, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 377, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 399, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=%F0%9F%87%B3%F0%9F%87%AC+in+Cape+Town+%F0%9F%87%BF%F0%9F%87%A6&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*(' in Cape Town ',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 426, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 421, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 1332, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 303, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 264, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 428, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 724, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\util\\retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=%F0%9F%87%B3%F0%9F%87%AC+in+Cape+Town+%F0%9F%87%BF%F0%9F%87%A6&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 387, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 543, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=%F0%9F%87%B3%F0%9F%87%AC+in+Cape+Town+%F0%9F%87%BF%F0%9F%87%A6&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 360, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 377, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 399, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=%F0%9F%87%B3%F0%9F%87%AC+in+Cape+Town+%F0%9F%87%BF%F0%9F%87%A6&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter swallowed an error after 2 retries. Called with (*(' in Cape Town ',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 426, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 421, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 1332, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 303, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\http\\client.py\", line 264, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 428, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 752, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 724, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\urllib3\\util\\retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=%F0%9F%87%B3%F0%9F%87%AC+in+Cape+Town+%F0%9F%87%BF%F0%9F%87%A6&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 387, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 543, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\requests\\adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=%F0%9F%87%B3%F0%9F%87%AC+in+Cape+Town+%F0%9F%87%BF%F0%9F%87%A6&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 360, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 377, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"C:\\Apps\\Anaconda\\lib\\site-packages\\geopy\\adapters.py\", line 399, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=%F0%9F%87%B3%F0%9F%87%AC+in+Cape+Town+%F0%9F%87%BF%F0%9F%87%A6&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>total_tweet</th>\n",
       "      <th>influence</th>\n",
       "      <th>username</th>\n",
       "      <th>location</th>\n",
       "      <th>followers</th>\n",
       "      <th>friends</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138203134</td>\n",
       "      <td>147567</td>\n",
       "      <td>706180</td>\n",
       "      <td>20</td>\n",
       "      <td>853747</td>\n",
       "      <td>AOC</td>\n",
       "      <td>Bronx + Queens, NYC</td>\n",
       "      <td>10989494</td>\n",
       "      <td>2958</td>\n",
       "      <td>40.809458</td>\n",
       "      <td>-73.793548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15088481</td>\n",
       "      <td>329320</td>\n",
       "      <td>436053</td>\n",
       "      <td>1549</td>\n",
       "      <td>765373</td>\n",
       "      <td>MikeHudema</td>\n",
       "      <td>Unceded Squamish Territory</td>\n",
       "      <td>131345</td>\n",
       "      <td>38822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36711022</td>\n",
       "      <td>150998</td>\n",
       "      <td>554973</td>\n",
       "      <td>27</td>\n",
       "      <td>705971</td>\n",
       "      <td>DanRather</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1772936</td>\n",
       "      <td>688</td>\n",
       "      <td>40.712728</td>\n",
       "      <td>-74.006015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>950477244</td>\n",
       "      <td>358553</td>\n",
       "      <td>323199</td>\n",
       "      <td>2706</td>\n",
       "      <td>681752</td>\n",
       "      <td>PaulEDawson</td>\n",
       "      <td>Glasgow, Scotland</td>\n",
       "      <td>57193</td>\n",
       "      <td>22793</td>\n",
       "      <td>55.860982</td>\n",
       "      <td>-4.248879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19725644</td>\n",
       "      <td>129920</td>\n",
       "      <td>437552</td>\n",
       "      <td>4</td>\n",
       "      <td>567472</td>\n",
       "      <td>neiltyson</td>\n",
       "      <td>New York City</td>\n",
       "      <td>14412201</td>\n",
       "      <td>39</td>\n",
       "      <td>40.712728</td>\n",
       "      <td>-74.006015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>28259151</td>\n",
       "      <td>326</td>\n",
       "      <td>652</td>\n",
       "      <td>7</td>\n",
       "      <td>978</td>\n",
       "      <td>Timpmurray</td>\n",
       "      <td>Sydney, New South Wales</td>\n",
       "      <td>4200</td>\n",
       "      <td>971</td>\n",
       "      <td>-33.854816</td>\n",
       "      <td>151.216454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>47739450</td>\n",
       "      <td>378</td>\n",
       "      <td>600</td>\n",
       "      <td>2</td>\n",
       "      <td>978</td>\n",
       "      <td>ByronYork</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "      <td>469012</td>\n",
       "      <td>1374</td>\n",
       "      <td>38.894992</td>\n",
       "      <td>-77.036558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>155240932</td>\n",
       "      <td>256</td>\n",
       "      <td>721</td>\n",
       "      <td>2</td>\n",
       "      <td>977</td>\n",
       "      <td>knightwatchman_</td>\n",
       "      <td>dev repository</td>\n",
       "      <td>8296</td>\n",
       "      <td>208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>827237152836685826</td>\n",
       "      <td>471</td>\n",
       "      <td>506</td>\n",
       "      <td>1</td>\n",
       "      <td>977</td>\n",
       "      <td>Dr_Woga</td>\n",
       "      <td>Lbeck, Deutschland</td>\n",
       "      <td>76703</td>\n",
       "      <td>76202</td>\n",
       "      <td>53.866444</td>\n",
       "      <td>10.684738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>21751177</td>\n",
       "      <td>173</td>\n",
       "      <td>804</td>\n",
       "      <td>16</td>\n",
       "      <td>977</td>\n",
       "      <td>thewritertype</td>\n",
       "      <td>Red Hackney</td>\n",
       "      <td>27479</td>\n",
       "      <td>1296</td>\n",
       "      <td>51.546819</td>\n",
       "      <td>-0.032907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id  retweet_count  like_count  total_tweet  influence  \\\n",
       "0              138203134         147567      706180           20     853747   \n",
       "1               15088481         329320      436053         1549     765373   \n",
       "2               36711022         150998      554973           27     705971   \n",
       "3              950477244         358553      323199         2706     681752   \n",
       "4               19725644         129920      437552            4     567472   \n",
       "...                  ...            ...         ...          ...        ...   \n",
       "4995            28259151            326         652            7        978   \n",
       "4996            47739450            378         600            2        978   \n",
       "4997           155240932            256         721            2        977   \n",
       "4998  827237152836685826            471         506            1        977   \n",
       "4999            21751177            173         804           16        977   \n",
       "\n",
       "             username                    location followers friends  \\\n",
       "0                 AOC         Bronx + Queens, NYC  10989494    2958   \n",
       "1          MikeHudema  Unceded Squamish Territory    131345   38822   \n",
       "2           DanRather                New York, NY   1772936     688   \n",
       "3         PaulEDawson           Glasgow, Scotland     57193   22793   \n",
       "4           neiltyson               New York City  14412201      39   \n",
       "...               ...                         ...       ...     ...   \n",
       "4995       Timpmurray     Sydney, New South Wales      4200     971   \n",
       "4996        ByronYork            Washington, D.C.    469012    1374   \n",
       "4997  knightwatchman_              dev repository      8296     208   \n",
       "4998          Dr_Woga         Lbeck, Deutschland     76703   76202   \n",
       "4999    thewritertype                 Red Hackney     27479    1296   \n",
       "\n",
       "       latitude   longitude  \n",
       "0     40.809458  -73.793548  \n",
       "1           NaN         NaN  \n",
       "2     40.712728  -74.006015  \n",
       "3     55.860982   -4.248879  \n",
       "4     40.712728  -74.006015  \n",
       "...         ...         ...  \n",
       "4995 -33.854816  151.216454  \n",
       "4996  38.894992  -77.036558  \n",
       "4997        NaN         NaN  \n",
       "4998  53.866444   10.684738  \n",
       "4999  51.546819   -0.032907  \n",
       "\n",
       "[5000 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# geocode address by geopy\n",
    "locator = geopy.Nominatim(user_agent= 'myGeocoder')\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "# 1 - conveneint function to delay between geocoding calls\n",
    "geocode = RateLimiter(locator.geocode, min_delay_seconds = 0.1)\n",
    "# 2- - create location column\n",
    "user['geocode'] = user['location'].apply(geocode)\n",
    "# 3 - create longitude, laatitude and altitude from location column (returns tuple)\n",
    "user['point'] = user['geocode'].apply(lambda loc: tuple(loc.point) if loc else None)\n",
    "# 4 - split point column into latitude, longitude and altitude columns\n",
    "user[['latitude', 'longitude', 'altitude']] = pd.DataFrame(user['point'].tolist(), index=user.index)\n",
    "user = user.drop(['point','geocode','altitude'], axis=1)\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.to_csv(r\"D:\\twarc\\climatetweetID\\tweets_prediction\\influence\\allusers_info\\output_3\\top5000.csv\")\n",
    "# Then go to R to select US users"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
