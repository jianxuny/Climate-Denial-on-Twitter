{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json_lines\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import lxml.etree as etree # to create gexl file\n",
    "import datetime\n",
    "\n",
    "import geopandas\n",
    "import geopy\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract tweet and retweet information\n",
    "\n",
    "def load_jsonl(file):\n",
    "    tweets = []\n",
    "    with open(file, 'rb') as f:\n",
    "        for tweet in json_lines.reader(f, broken=True):             \n",
    "            if 'retweeted_status' in tweet:           \n",
    "                reduced_tweet = {'retweeting_username': tweet['user']['screen_name'],\n",
    "                                 'retweeted_username' : tweet['retweeted_status']['user']['screen_name']}          \n",
    "                tweets.append(reduced_tweet)            \n",
    "        return (tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all retweets from large (40GB) jsonl files\n",
    "#retweets_all = load_jsonl(r\"D:\\twarc\\climatetweetID\\sna\\tweets_small.jsonl\")\n",
    "retweets_all = load_jsonl(r\"D:\\twarc\\climatetweetID\\hydratefile\\climate_id_03.jsonl\")\n",
    "with open(r\"D:\\twarc\\climatetweetID\\sna\\coretweet_network\\01_all_retweets\\all_retweet_3.txt\", \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(retweets_all, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top influential user's name\n",
    "#top_users = pd.read_csv(r\"D:\\twarc\\climatetweetID\\tweets_prediction\\influence\\allusers_info\\output_3\\top1000.csv\", dtype = object)      \n",
    "top_users = pd.read_csv(r\"E:\\twarc\\climatetweetID\\tweets_prediction\\influence\\allusers_info\\output_3\\top5000_uslabelled.csv\", dtype = object)\n",
    "top_users = top_users.dropna(subset = ['NAME'])\n",
    "user_name = top_users['username']\n",
    "user_name = user_name[:1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only influencers' retweets\n",
    "# https://www.jianshu.com/p/a3f60ceff8bf\n",
    "# https://stackoverflow.com/questions/16597265/appending-to-an-empty-dataframe-in-pandas\n",
    "for i in range(0,4):    \n",
    "    with open(r\"E:\\twarc\\climatetweetID\\sna\\coretweet_network\\01_all_retweets\\all_retweet_%d.txt\" % (i), \"rb\") as fp:   #Pickling\n",
    "        tweets = pickle.load(fp)        \n",
    "    tweets = pd.DataFrame(tweets)\n",
    "    infl_tweet = pd.DataFrame()\n",
    "    for name in user_name.tolist():\n",
    "        subset = tweets[tweets['retweeted_username'] == name]\n",
    "        infl_tweet = infl_tweet.append(subset)    \n",
    "    with open(r\"E:\\twarc\\climatetweetID\\sna\\coretweet_network\\02_influencer_retweets\\infl_retweet_1200_%d.txt\" % (i), \"wb\") as fp:\n",
    "        pickle.dump(infl_tweet, fp)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by influencer and retweeting users\n",
    "infl_tweet = pd.DataFrame()\n",
    "for i in range(0,4):\n",
    "    with open(r\"E:\\twarc\\climatetweetID\\sna\\coretweet_network\\02_influencer_retweets\\infl_retweet_%d.txt\" % (i), \"rb\") as fp:   #Pickling\n",
    "        subset = pickle.load(fp)        \n",
    "    infl_tweet = infl_tweet.append(subset)    \n",
    "retweet_summary = infl_tweet.groupby(['retweeting_username','retweeted_username']).size()\n",
    "retweet_summary = pd.DataFrame(retweet_summary)\n",
    "retweet_summary.reset_index(inplace = True)\n",
    "retweet_summary = retweet_summary.rename(columns = {0: \"sum_tweets\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the co-retweet matrix!\n",
    "# https://stackoverflow.com/questions/42806398/create-adjacency-matrix-for-two-columns-in-pandas-dataframe\n",
    "# https://stackoverflow.com/questions/51217328/turn-pandas-dataframe-into-int32-numpy-matrix\n",
    "\n",
    "df = pd.crosstab(retweet_summary.retweeting_username, retweet_summary.retweeted_username)\n",
    "#df.to_csv(r\"D:\\twarc\\climatetweetID\\sna\\coretweet_network\\03_coretweet_matrix\\coretweet.csv\")\n",
    "#df = pd.read_csv(r\"D:\\twarc\\climatetweetID\\sna\\coretweet_network\\03_coretweet_matrix\\coretweet.csv\")\n",
    "re_mat = np.asmatrix(df.values)\n",
    "co_mat = re_mat.T*re_mat\n",
    "#pd.DataFrame(co_mat).to_csv(r\"D:\\twarc\\climatetweetID\\sna\\coretweet_network\\03_coretweet_matrix\\co_mat.csv\")\n",
    "column_name =  list(df.columns)\n",
    "df_comat = pd.DataFrame(co_mat)\n",
    "df_comat.columns = column_name\n",
    "df_comat.index = column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# influencer's name and retweeting user's name\n",
    "# export Gephi files\n",
    "pair_user = list(itertools.combinations(column_name, 2))\n",
    "co_retweet_matrix = []\n",
    "for i in pair_user:\n",
    "    no_coretweet = df_comat.at[i[0], i[1]]\n",
    "    new_pair = [i[0], i[1], no_coretweet]    \n",
    "    co_retweet_matrix.append(new_pair)\n",
    "co_retweet_matrix = pd.DataFrame(co_retweet_matrix, columns = ['userA', 'userB', 'no_coretweet'])\n",
    "co_retweet_matrix.to_csv(r\"E:\\twarc\\climatetweetID\\sna\\coretweet_network\\04_Gephi\\edge_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userA</th>\n",
       "      <th>userB</th>\n",
       "      <th>no_coretweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1followernodad</td>\n",
       "      <td>4everNeverTrump</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1followernodad</td>\n",
       "      <td>ABC</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1followernodad</td>\n",
       "      <td>ABCPolitics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1followernodad</td>\n",
       "      <td>AOC</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1followernodad</td>\n",
       "      <td>AP_Politics</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76631</th>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>weatherchannel</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76632</th>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>wesley_jordan</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76633</th>\n",
       "      <td>wattsupwiththat</td>\n",
       "      <td>weatherchannel</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76634</th>\n",
       "      <td>wattsupwiththat</td>\n",
       "      <td>wesley_jordan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76635</th>\n",
       "      <td>weatherchannel</td>\n",
       "      <td>wesley_jordan</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76636 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 userA            userB  no_coretweet\n",
       "0       1followernodad  4everNeverTrump            21\n",
       "1       1followernodad              ABC            17\n",
       "2       1followernodad      ABCPolitics             2\n",
       "3       1followernodad              AOC           222\n",
       "4       1followernodad      AP_Politics            12\n",
       "...                ...              ...           ...\n",
       "76631   washingtonpost   weatherchannel           634\n",
       "76632   washingtonpost    wesley_jordan           655\n",
       "76633  wattsupwiththat   weatherchannel             5\n",
       "76634  wattsupwiththat    wesley_jordan             1\n",
       "76635   weatherchannel    wesley_jordan           132\n",
       "\n",
       "[76636 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_retweet_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gexf(tweets, filename):\n",
    "    attr_qname = etree.QName(\"http://www.w3.org/2001/XMLSchema-instance\", \"schemaLocation\")\n",
    "    gexf = etree.Element('gexf',\n",
    "                         {attr_qname : 'http://www.gexf.net/1.3draft  http://www.gexf.net/1.3draft/gexf.xsd'},\n",
    "                         nsmap={None : 'http://graphml.graphdrawing.org/xmlns/graphml'},\n",
    "                         version = '1.3')\n",
    "    graph = etree.SubElement(gexf,'graph', defaultedgetype = 'undirected', mode =  'dynamic', timeformat='datetime')\n",
    "    attributes = etree.SubElement(graph, 'attributes', {'class' : 'node', 'mode' : 'static'})  \n",
    "    \n",
    "    nodes = etree.SubElement(graph, 'nodes')\n",
    "    edges = etree.SubElement(graph, 'edges')\n",
    "\n",
    "    for index, tweet in tweets.iterrows():\n",
    "        node = etree.SubElement(nodes,'node', id = tweet['userA'], Label = tweet['userA'])\n",
    "        node = etree.SubElement(nodes,'node', id = tweet['userB'], Label = tweet['userB'])\n",
    "        etree.SubElement(edges, 'edge',\n",
    "                         {'source' : tweet['userA'],\n",
    "                          'target' : tweet['userB'],\n",
    "                          'no_cort': str(tweet['no_coretweet'])})\n",
    "        \n",
    "\n",
    "    with open(filename, 'w', encoding='utf-8')as f:\n",
    "        f.write(etree.tostring(gexf, encoding='utf8', method='xml').decode('utf-8'))\n",
    "    print('Created gexf.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created gexf.\n"
     ]
    }
   ],
   "source": [
    "create_gexf(co_retweet_matrix, r'D:\\twarc\\climatetweetID\\sna\\coretweet_network\\03_coretweet_matrix\\full_test_network.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodetable = pd.read_csv(r\"D:\\twarc\\climatetweetID\\sna\\coretweet_network\\04_Gephi\\nodetable_o.csv\")\n",
    "node_newatt = pd.read_csv(r\"D:\\twarc\\climatetweetID\\sna\\coretweet_network\\04_Gephi\\topuser_info.csv\")\n",
    "nodetable.set_index('Id').join(node_newatt.set_index('username')).to_csv(r\"D:\\twarc\\climatetweetID\\sna\\coretweet_network\\04_Gephi\\new_nodetable.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
