{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXaGNqJpIB37"
      },
      "source": [
        "## **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPrlftLjHOq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be4a9037-1b2b-4b64-ad85-bbb38aafdbb5"
      },
      "source": [
        "# call colab\n",
        "from google.colab import drive\n",
        "\n",
        "# mount google drive locally\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# import required libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "! pip install ftfy\n",
        "\n",
        "import torch\n",
        "torch.cuda.get_device_name(0)\n",
        "\n",
        "import os\n",
        "# 此处为google drive中的文件路径,drive为之前指定的工作根目录，要加上\n",
        "os.chdir(\"drive/My Drive/tweet-stance-prediction-master/transformer-openai\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26squG4S-13W"
      },
      "source": [
        "# clean training dataset\n",
        "trainingdata = pd.read_csv(\"/content/drive/My Drive/tweet-stance-prediction-master/data/training_sample.csv\")\n",
        "full_text_list = []\n",
        "for index, rows in trainingdata['Tweet'].iteritems():\n",
        "    rows = re.sub('\\\"{5,}', '', rows) \n",
        "    rows = re.sub(\"\\n|\\r\", \"\", rows)     \n",
        "    full_text_list.append(rows)\n",
        "trainingdata['Tweet'] = full_text_list\n",
        "#trainingdata = trainingdata.drop(['state'],axis=1)\n",
        "trainingdata.to_csv(\"/content/drive/My Drive/tweet-stance-prediction-master/data/clean_training_sample.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictdata = pd.read_csv(\"/content/drive/My Drive/tweet-stance-prediction-master/data/MI.csv\")\n",
        "predictdata = predictdata[predictdata['full_text'].notnull()]\n",
        "full_text_list = []\n",
        "for index, rows in predictdata['full_text'].iteritems():\n",
        "  rows = re.sub('\\\"{2,}', '\"', rows) \n",
        "  rows = re.sub(\"\\n|\\r\", \"\", rows) \n",
        "  full_text_list.append(rows)\n",
        "predictdata['Tweet'] = full_text_list\n",
        "#predictdata[\"text\"] = predictdata['Tweet']  \n",
        "#predictdata = predictdata['Tweet']  \n",
        "predictdata[\"Stance\"] = \"FAVOR\"\n",
        "predictdata.to_csv(\"/content/drive/My Drive/tweet-stance-prediction-master/data/clean_tweet_data.csv\")"
      ],
      "metadata": {
        "id": "t8DlOX_vSeVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 train_stance.py --dataset stance --desc stance --submit --data_dir ../data --submission_dir MI\n",
        "! python3 parse_output.py ../data/clean_tweet_data.csv MI/stance.tsv ../results/MI_class.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIoX5Jqfykqa",
        "outputId": "59ebe108-ea5c-48a3-bae4-f9920b237c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(afn='gelu', analysis=False, attn_pdrop=0.1, b1=0.9, b2=0.999, bpe_path='model/vocab_40000.bpe', clf_pdrop=0.1, data_dir='../data', dataset='stance', desc='stance', e=1e-08, embd_pdrop=0.1, encoder_path='model/encoder_bpe_40000.json', l2=0.01, lm_coef=0.5, log_dir='log/', lr=6.25e-05, lr_schedule='warmup_linear', lr_warmup=0.002, max_grad_norm=1, n_batch=8, n_ctx=512, n_embd=768, n_head=12, n_iter=3, n_layer=12, n_transfer=12, n_valid=374, opt='adam', resid_pdrop=0.1, save_dir='save/', seed=42, submission_dir='MI', submit=True, topic=None, vector_l2=False)\n",
            "device cuda n_gpu 1\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1899: UserWarning: [W123] Argument disable with value ['parser', 'tagger', 'ner', 'textcat'] is used instead of ['senter'] as specified in the config. Be aware that this might affect other components in your pipeline.\n",
            "  config_value=config[\"nlp\"][key],\n",
            "Encoding dataset...\n",
            "  0%|                                                  | 0/5390 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "Loading weights...\n",
            "running epoch 0\n",
            "  0%|                                                   | 0/673 [00:00<?, ?it/s]/content/drive/MyDrive/tweet-stance-prediction-master/transformer-openai/opt.py:87: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n",
            "  exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
            "Logging\n",
            "1 673 3.719 11.237 94.73 83.68\n",
            "running epoch 1\n",
            "Logging\n",
            "2 1346 0.895 26.630 98.74 85.01\n",
            "running epoch 2\n",
            "Logging\n",
            "3 2019 0.282 34.442 99.85 86.72\n"
          ]
        }
      ]
    }
  ]
}