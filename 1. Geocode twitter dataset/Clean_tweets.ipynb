{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "celtic-mitchell",
   "metadata": {},
   "source": [
    "# Clean tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "specialized-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import emoji\n",
    "import json_lines\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "smoking-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# ---- DEFINE HELPER FUNCTION ----\n",
    "# --------------------------------\n",
    "\n",
    "# 1 - TEXT PROCESSING\n",
    "def clean_text(text):    \n",
    "    if type(text) == str:\n",
    "        allchars = [str for str in text]\n",
    "        emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI]\n",
    "        clean_text = ' '.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n",
    "        clean_text = clean_text.replace('\\n\\r', ' ') # remove line breaks\n",
    "        clean_text = re.sub(r\"\\bhttps://t.co/\\w+\", '', clean_text) # remove urls\n",
    "        clean_text = re.sub(\"&amp\", '', clean_text) # clean punctuations\n",
    "        clean_text = re.sub(\"’\", \"'\", clean_text)\n",
    "        clean_text = re.sub(\"\\'\", \"'\", clean_text)        \n",
    "        clean_text = re.sub(\"‘\", \"'\", clean_text)\n",
    "        clean_text = re.sub(\"”\", '\"', clean_text) \n",
    "        clean_text = re.sub(\"“\", '\"', clean_text) \n",
    "        clean_text = re.sub(\"—\", '-', clean_text)\n",
    "        clean_text = re.sub(\"&gt\", '', clean_text)        \n",
    "        clean_text = re.sub('\"{2,}', '\"', clean_text)\n",
    "        clean_text = re.sub(\"'{2,}\", \"'\", clean_text)\n",
    "        clean_text = re.sub(\" {2,}\", \" \", clean_text)        \n",
    "        \n",
    "    if type(text) != str:        \n",
    "        clean_text = None\n",
    "    return clean_text\n",
    "\n",
    "# 2 - TIME PROCESSING\n",
    "# covert 'created_at' column to datetime format\n",
    "def time_to_date(time_str):\n",
    "    new_time_dt     = []\n",
    "    new_time_string = time_str.replace('+0000 ','')  \n",
    "    i_time = datetime.datetime.strptime(new_time_string, '%a %b %d %H:%M:%S %Y')\n",
    "    i_time_str = datetime.datetime.strftime(i_time, '%m/%d/%Y')\n",
    "    new_time_dt = datetime.datetime.strptime(i_time_str, '%m/%d/%Y')\n",
    "    \n",
    "    return new_time_dt\n",
    "\n",
    "# 3 - EXTRACT ATTRIBUTES FROM JSONL\n",
    "def load_jsonl(file, total_line):\n",
    "    tweets = []\n",
    "    with open(file, 'rb') as f:\n",
    "        for tweet in tqdm(json_lines.reader(f, broken=True), total = total_line):\n",
    "            reduced_tweet = {\"created_at\" : time_to_date(tweet[\"created_at\"]),\n",
    "                             \"id_str\"     : tweet[\"id_str\"],\n",
    "                             \"full_text\"  : clean_text(tweet[\"full_text\"]), # clean tweets\n",
    "                             \"retweet_count\" : tweet[\"retweet_count\"],\n",
    "                             \"favorite_count\": tweet[\"favorite_count\"],\n",
    "                             \"lang\"       : tweet[\"lang\"],                                                          \n",
    "                             \"user_id_str\"  : tweet[\"user\"][\"id_str\"],\n",
    "                             \"user_name\"    : tweet[\"user\"][\"screen_name\"],\n",
    "                             \"user_location\": clean_text(tweet[\"user\"][\"location\"]), # clean address in user profiles\n",
    "                             \"user_follower\": tweet[\"user\"][\"followers_count\"]}\n",
    "            \n",
    "            if tweet[\"place\"] is not None:\n",
    "                reduced_tweet[\"place_type\"] = tweet[\"place\"][\"place_type\"]\n",
    "                reduced_tweet[\"place_name\"] = tweet[\"place\"][\"full_name\"]\n",
    "                reduced_tweet[\"place_country\"] = tweet[\"place\"][\"country\"]\n",
    "                \n",
    "            if tweet[\"coordinates\"] is not None:\n",
    "                reduced_tweet[\"coord_lon\"]  = tweet[\"coordinates\"][\"coordinates\"][0]\n",
    "                reduced_tweet[\"coord_lat\"]  = tweet[\"coordinates\"][\"coordinates\"][1]\n",
    "                                         \n",
    "            if \"retweeted_status\" in tweet:           \n",
    "                reduced_tweet[\"full_text\"]            = clean_text(tweet['retweeted_status']['full_text'])        \n",
    "                reduced_tweet[\"retweeted_created_at\"] = time_to_date(tweet[\"retweeted_status\"][\"created_at\"])\n",
    "                reduced_tweet[\"retweeted_id_str\"]     = tweet['retweeted_status']['id_str']\n",
    "                reduced_tweet[\"retweeted_user_id\"]    = tweet[\"retweeted_status\"][\"user\"][\"id_str\"]\n",
    "                reduced_tweet[\"retweeted_username\"]   = tweet[\"retweeted_status\"][\"user\"][\"screen_name\"]               \n",
    "                \n",
    "            if \"quoted_status\" in tweet:                           \n",
    "                reduced_tweet[\"quoted_created_at\"] = time_to_date(tweet[\"quoted_status\"][\"created_at\"])\n",
    "                reduced_tweet[\"quoted_id_str\"]     = tweet['quoted_status']['id_str']     \n",
    "                reduced_tweet[\"quoted_user_id\"]    = tweet[\"quoted_status\"][\"user\"][\"id_str\"]\n",
    "                reduced_tweet[\"quoted_username\"]   = tweet['quoted_status']['user']['screen_name']                \n",
    "                \n",
    "            if tweet[\"in_reply_to_status_id_str\"] is not None:\n",
    "                reduced_tweet[\"reply_status\"]   = tweet[\"in_reply_to_status_id_str\"]\n",
    "                reduced_tweet[\"reply_user_id\"]  = tweet[\"in_reply_to_user_id_str\"]\n",
    "                reduced_tweet[\"reply_username\"] = tweet[\"in_reply_to_screen_name\"]\n",
    "\n",
    "            tweets.append(reduced_tweet)      \n",
    "        return (tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beginning-basis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7098819it [10:34, 11194.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 7098819/7098819 [38:41<00:00, 3057.60it/s]\n",
      "6944479it [11:28, 10079.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 6944479/6944479 [42:03<00:00, 2751.97it/s]\n",
      "6592348it [10:04, 10908.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 6592348/6592348 [35:22<00:00, 3105.99it/s]\n",
      "6729398it [10:12, 10994.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 6729398/6729398 [36:41<00:00, 3056.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# ---- EXTRACT ATTRIBUTES FROM 4 LARGE RAW JSONL FILES ----\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "raw_tweet_path = \"D:/DL_tweets_data/0_raw_jsonl\" # replace this directory with your own\n",
    "reduced_tweet_path = \"D:/DL_tweets_data/1_reduced_csv\" # replace this directory with your own \n",
    " \n",
    "filenum = 0    \n",
    "for file_name in os.listdir(raw_tweet_path):\n",
    "    file_path  = raw_tweet_path + \"/\" + file_name\n",
    "    \n",
    "    \n",
    "    # calculate total lines in each jsonl file\n",
    "    with open(file_path, 'rb') as f:\n",
    "        total_line = sum(1 for tweet in tqdm(json_lines.reader(f, broken=True)))  \n",
    "        \n",
    "    # use the load_jsonl function to extract attributes  \n",
    "    reduced_tweet = load_jsonl(file_path, total_line)\n",
    "    reduced_tweet_df = pd.DataFrame(reduced_tweet)\n",
    "        \n",
    "    # save python lists as csv files\n",
    "    filenum += 1\n",
    "    reduced_tweet_df.to_csv(reduced_tweet_path + \"/\" + \"reduced_tweet_%d.csv\" % (filenum), index= False)\n",
    "    \n",
    "    del reduced_tweet, reduced_tweet_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
